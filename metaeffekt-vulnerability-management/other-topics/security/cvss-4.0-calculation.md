> [Documentation](../../../README.md) >
> [Vulnerability Management](../../vulnerability-management.md) >
> CVSS 4.0 Calculation

# CVSS 4.0 Calculation

> [Introduction](#introduction) -
> [High-Level Calculation](#high-level-calculation)

## Introduction

> *written from the perspective of Yan Wittmann*

The lack of a proper documentation (that was even more confusingly written when I implemented my version back then and contained several errors in the numbers) and the discrepancy between the documentation and the poorly written reference implementation made it pretty hard to figure out how the calculations work.

It took me about 3 weeks to finish our implementation.
To test it, I created a dataset of ~100.000 test vectors that cover several special cases and when it passed on all of them, I was pretty confident that it should be correct now.

Another confusing aspect has been brough up by Thomas Schmit from the BSI in an issue on our TS implementation: https://github.com/org-metaeffekt/metaeffekt-universal-cvss-calculator/issues/2  
Namely, that the JSON Schema defines more than just a base score.
We have not heard back from the FIRST since contacting them about it several months ago.

## High-Level Calculation

- [Our Java Implementation](https://github.com/org-metaeffekt/metaeffekt-core/blob/dd6599634a4b6cec6b166e7ce364f33813d9a32a/libraries/ae-security/src/main/java/org/metaeffekt/core/security/cvss/v4P0/Cvss4P0.java)
- [Our TypeScript Implementation](https://github.com/org-metaeffekt/metaeffekt-universal-cvss-calculator)
- [Link to CVSS 3.1 Specification](https://www.first.org/cvss/v3.1/specification-document#CVSS-v3-1-Equations)  
- [Link to CVSS 4.0 Specification](https://www.first.org/cvss/v4.0/specification-document#CVSS-v4-0-Scoring-using-MacroVectors-and-Interpolation)

CVSS version 4.0 behaves somewhat differently:
It defines only a single calculable score and does not use static formulas like in 2.0 and 3.1,
but rather employs some higher mathematical concepts.
These changes were made deliberately: According to the documentation and development history of CVSS 4.0,
the goal was not only to simplify the interpretation of results (and reduce confusion) by reducing to a single score,
but also to address the criticism that the scoring formulas in previous versions were not intuitive due to their rather
abstract predefined formulas.
Therefore, a different approach was chosen for 4.0.

The 15 million possible vectors of this version were automatically reduced from 32 metric dimensions to a 6-dimensional
space with 270 so-called "MacroVectors" through various rules,
with each dimension being defined by its own rules as an "Equivalence Group".
These were presented to an expert group of 50 participants, who manually ordered them by severity into an absolute list.
Using this dataset, an average list of vectors with ascending severity was created,
reflecting the current opinions of security experts, thereby addressing the criticism of formula abstraction.
These abstracted vectors could then be linearly assigned static CVSS scores from 0 to 10 in a lookup table.

To use this lookup table for score calculation from an initial input vector,
the vector must first be reduced from its 32 metrics to a 6-dimensional MacroVector.
The 270 scores in the lookup table are somewhat limited in representing the diversity and
detail of all 15 million combinations.
Therefore, an interpolation step back into the larger dimensional space must added as a second step,
which is responsible for most of the calculation logic and complexity.

The 6 Equivalence Groups each define some rules, specifying which metrics they encompass and how they contribute to metric classification.
Listing 3.10 shows the EQ class and one implementation for the second group.
They effectively represent the rules and functions defined in the specification.

```typescript
class EQ {
  level: string;
  vectorDepth: number;
  highestSeverityVectors: ICvss4P0[] = [];
  predicate: (vector: ICvss4P0) => boolean;
}

public static EQ2_DEFINITIONS: EQ[] = [
  new EQ("0", 1, ["AC:L/AT:N"], 
    vector => vector.get("AC") === "L" && vector.get("AT") === "N"),
  new EQ("1", 2, ["AC:H/AT:N", "AC:L/AT:P"], 
    vector => !(vector.get("AC") === "L" && vector.get("AT") === "N"))
];
```

Now, these two steps are discussed at a level to have a balance between complexity and comprehensibility.
Before delving into the exact formulas, something that confused me at first is that the calculations contain two completely different scales with various meanings that need to be explained:

- **Severity Distance Scale**: This scale relates to the vector metrics and their possible values.
The smallest possible change of ±1 on this scale represents a change of a single metric value up or down (+1 = more severe, −1 = less severe).
Since only distances to the upper boundary of individual MacroVectors are effectively calculated, it can only take positive values.
- **CVSS Score Scale**: As mentioned, this scale represents the severity of the vulnerability in a range from 0 to 10, with higher values indicating more severe vulnerabilities.
The smallest possible change on this scale is 0.1.

These will be used in the following paragraphs and mentioned whenever applicable.

The following formulas, although fully derived from the implementation, are not listed this way in the standard as the standard focuses more on the (mathematical) concepts behind the calculation rather than the actual calculation details.
The desired score is defined by the function `ScoreInterpolated(V)`.

```
ScoreInterpolated(V) = ScoreBase(MV) − Mean(ScoreEQ(EQ1), ..., ScoreEQ(EQ6))
ScoreEQ(EQ) = ProportionDistance(V, EQ) × ScoreRange(MV, EQ)
ProportionDistance(V, EQ) = SeverityDistance(V, MV) / Depth(MV)
```

With this, the following values and formulas can be defined:

- **MV** represents the MacroVector derived from the original vector.
- **EQ** is referred to as an equivalence group with a collection of definitions and functions defining when a subset of vector metrics belongs to a group, and maintaining a list of highest severity vectors meeting their criteria.
- **ScoreInterpolated(V)** is the target of the calculation, the final score for the vector.
  It combines the base score with the average adjustments by the equivalence groups.
- **ScoreBase(MV)** is the base score obtained by looking up in the lookup table.
- **Mean(scores)** (CVSS Score Scale) calculates the average score over all EQ groups applicable to the vector.
  Not always can an EQ be calculated for a vector.
- **ScoreEQ(EQ)** (CVSS Score Scale) calculates a proportional score adjustment for the current EQ group.
  This is calculated by multiplying a value between 0 and 1 (see ProportionDistance) and the score range, i.e., the maximum score difference within the EQ group.
- **ProportionDistance(V, EQ)** is a value between 0 and 1 (0-100%) and defines how far the vector is from the highest severity within the EQ group, in relation to the entire severity range of the MacroVector.
- **SeverityDistance(V, MV)** (Severity Distance Scale) is the number of metric value changes needed to move the vector V from the vector with the highest severity within the same MacroVector.
- **Depth(MV)** (Severity Distance Scale) is the total number of metric value changes within a MacroVector from its lowest to highest severity vector.
  This varies for each MacroVector as each can have different widths.
- **ScoreRange(MV, EQ)** (CVSS Score Scale) is the maximum score difference within the MacroVector for a given EQ group.
  It represents the effective score range within a MacroVector.

Listing 3.11 now shows pseudocode for score calculation, as implemented in the Cvss4P0 class in TypeScript.

```python
def calculateScore(vector):
    if not baseDefined(vector) or noImpact(vector):
        return 0.0

    # encapsulated implementations for equivalence groups handling
    eqGroups = getEquivalenceGroups()

    macro = getMacroVector(vector)
    baseScore = lookupTableScore(macro)

    # collect vectors with highest severity from each equivalence group
    highestSevVectors = [group.getSevereVectors(macro) for group in eqGroups]

    # since each group may have multiple highest vectors, generate all permutations
    combinations = generateCvssPermutations(highestSevVectors)
    if combinations.isEmpty():
        return 0.0 # no max vectors found, does not happen in practice

    # the severity distances for all metrics between each combination and the input vector are
    # calculated. the first permutation with a combined positive severity distance is selected.
    for combination in combinations:
        severityDistances = calculateSeverityDistances(combination) # map<metric, distance>
        if sum(severityDistances) > 0:
            break

    # calculate the average of all proportional adjustments for all applicable groups
    adjustment = AverageCalculator()
    for group in eqGroups:
        lessSevereMacro = group.nextLowerMacro(macro)
        lowerScore = group.lookupScoresForNextLowerMacro(lessSevereMacro)
        # lowerScore is NaN if the current macro’s group is already the lowest,
        # leading to available Severity Reduction also potentially becoming NaN
        availableSeverityReduction = baseScore - lowerScore

        # all depth values are precalculated and defined by the specification
        depth = group.macroDepth(macro)
        distanceToHighest = sum(group.filterRelevantMetrics(severityDistances))

        # NaN is purposefully used as an indicator by the specification
        if not isNaN(availableSeverityReduction) and depth != 0.0:
            distancePercentageToNext = distanceToHighest / depth
            normalizedDistance = distancePercentageToNext * availableSeverityReduction
            adjustment.add(normalizedDistance)

    adjustedScore = baseScore - adjustment.averageOrDefault(0)
    return adjustScoreRange(adjustedScore)
```
